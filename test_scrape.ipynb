{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1f3633b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import date, datetime, timedelta\n",
    "import os\n",
    "import errno\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import time\n",
    "import db_func\n",
    "\n",
    "DEBUG = False\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "team_abbr = {'Atlanta Hawks':'ATL', 'Boston Celtics' : 'BOS', 'Brooklyn Nets': 'NJN',\n",
    "\t\t\t'Charlotte Hornets': 'CHA', 'Chicago Bulls':'CHI','Cleveland Cavaliers':'CLE',\n",
    "\t\t\t'Dallas Mavericks':'DAL','Denver Nuggets':'DEN', 'Detroit Pistons':'DET',\n",
    "\t\t\t'Golden State Warriors':'GSW','Houston Rockets':'HOU','Indiana Pacers':'IND',\n",
    "\t\t\t'Los Angeles Clippers':'LAC','Los Angeles Lakers':'LAL','Memphis Grizzlies':'MEM',\n",
    "\t\t\t'Miami Heat':'MIA','Milwaukee Bucks':'MIL','Minnesota Timberwolves':'MIN',\n",
    "\t\t\t'New Orleans Pelicans':'NOH','New York Knicks':'NYK','Oklahoma City Thunder':'OKC',\n",
    "\t\t\t'Orlando Magic':'ORL','Philadelphia 76ers':'PHI','Phoenix Suns':'PHO',\n",
    "\t\t\t'Portland Trail Blazers':'POR','Sacramento Kings':'SAC','San Antonio Spurs':'SAS',\n",
    "\t\t\t'Toronto Raptors':'TOR','Utah Jazz':'UTA','Washington Wizards':'WAS'}\n",
    "\n",
    "\n",
    "def scrape_matches(seasons):\n",
    "\t\"\"\"\n",
    "    scrape_matches saves the html page on bbref that lists all the games in a season\n",
    "\t\n",
    "\tArgs:\n",
    "\t\t:param seasons: list of seasons to scrape where season is the year \n",
    "\t\t\tthe seasons starts in \n",
    "\t\n",
    "\t:side effect: saves the respective html page as bs4_html/seasons[i].html\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\ttry:\n",
    "\t\tfor i in range(len(seasons)):\n",
    "\t\t\tfilename = os.path.join(os.getcwd(),\"bs4_html/match_list/\" \\\n",
    "\t\t\t+ \"/\" +seasons[i][0]+\".html\")\n",
    "\t\t\tif os.path.exists(filename):\n",
    "\t\t\t\treturn\n",
    "\t\t\turl = \"https://www.basketball-reference.com/leagues/NBA_\" + seasons[i][0] \\\n",
    "\t\t\t\t+ \"_games.html\"\n",
    "\t\t\texception = True\n",
    "\t\t\tprint(url)\n",
    "\t\t\twhile(exception):\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tresponse = requests.request(\"GET\", url)\n",
    "\t\t\t\t\tsoup = BeautifulSoup(response.content, 'html.parser')\n",
    "\t\t\t\t\texception = False\n",
    "\t\t\t\texcept requests.exceptions.RequestException as e:\n",
    "\t\t\t\t\tprint(e)\n",
    "\t\t\t\t\ttime.sleep(10)\n",
    "\t\t\t\t\texception = True\n",
    "\t\t\tif not os.path.isdir(\"bs4_html\"):\n",
    "\t\t\t\tos.makedirs(\"bs4_html\")\n",
    "\t\t\n",
    "\t\t\tos.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "\t\t\twith open(filename, \"w\", encoding='utf-8') as f:\n",
    "\t\t\t\tf.write(str(soup))\n",
    "\texcept Exception as err:\n",
    "\t\tprint(err)\n",
    "\n",
    "\n",
    "\n",
    "def scrape_all_boxscores():\n",
    "\t\"\"\"\n",
    "    scrape_all_boxscores saves the \n",
    "\n",
    "\t:param seasons: \n",
    "\t:side effect: \n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\t\n",
    "\n",
    "\n",
    "def scrape_boxscore_html(team, date):\n",
    "\t\"\"\"\n",
    "    save_boxscore_html saves the html page for a given match (boxscores)\n",
    "\t\n",
    "\tArgs: \n",
    "\t\tparam team: home team of match\n",
    "\t\tparam date: date of match\n",
    "\t\n",
    "\t:side effect: saves the respective html page in bs4_html/boxscores/date+team.html\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\ttry:\n",
    "\t\turl = \"https://www.basketball-reference.com/boxscores/\" + date + team + \".html\"\n",
    "\t\texception = True\n",
    "\t\n",
    "\t\twhile(exception):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tresponse = requests.request(\"GET\", url)\n",
    "\t\t\t\tsoup = BeautifulSoup(response.content, 'html.parser')\n",
    "\t\t\t\texception = False\n",
    "\t\t\texcept requests.exceptions.RequestException as e:\n",
    "\t\t\t\tprint(e)\n",
    "\t\t\t\ttime.sleep(20)\n",
    "\t\t\t\texception = True\n",
    "\t\tif not os.path.isdir(\"bs4_html\"):\n",
    "\t\t\tos.makedirs(\"bs4_html\")\n",
    "\t\tfilename = os.path.join(os.getcwd(),\"bs4_html/boxscores/\" \\\n",
    "\t\t\t+ \"/\" +date+team+\".html\")\n",
    "\t\tos.makedirs(os.path.dirname(filename), exist_ok=True)\n",
    "\t\twith open(filename, \"w\", encoding='utf-8') as f:\n",
    "\t\t\tf.write(str(soup))\n",
    "\texcept Exception as err:\n",
    "\t\tprint(err)\n",
    "\n",
    "def save_all_player_performances(season):\n",
    "\tfile_path = 'csv/' + season + '/match_list.csv'\n",
    "\tdf = pd.read_csv(file_path)\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\tprint(row['date'], row['home'])\n",
    "\n",
    "\n",
    "def match_list_to_csv(match_list_html):\n",
    "\t\"\"\"\n",
    "    matches_to_csv saves the html page for a given match (boxscores)\n",
    "\n",
    "\tArgs: \n",
    "\t\t:param match_list_html: html of match lists \n",
    "\t\t\tbs4_html/match_list/year.html\n",
    "\t\n",
    "\t:side effect: csv with all matches in given season/year\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\ttry:\n",
    "\t\twith open(match_list_html, 'r', encoding=\"utf8\") as f:\n",
    "\t\t\tcontents = f.read()\n",
    "\t\t\tsoup = BeautifulSoup(contents, 'lxml')\n",
    "\n",
    "\t\tmatch_urls = soup.find_all(\\\n",
    "\t\t\thref=re.compile('\\/leagues\\/NBA_[0-9]{4}_games-[A-Za-z]{1,}.html'))\n",
    "\t\tmatch_urls = [re.findall('\\/leagues\\/NBA_[0-9]{4}_games-[A-Za-z]{1,}.html',\\\n",
    "\t\t\t str(match_urls[i]))[0] for i in range(len(match_urls))]\n",
    "\t\tseason = re.findall('[0-9]{4}', match_list_html)[0]\n",
    "\t\tdirectory = \"csv/\" + season\n",
    "\t\tif not os.path.isdir(directory):\n",
    "\t\t\tos.makedirs(directory)\n",
    "\t\tfile_path = directory+\"/\"+\"match_list.csv\"\n",
    "\t\tif os.path.exists(file_path):\n",
    "\t\t\tos.remove(file_path)\n",
    "\t\tfor i in range(len(match_urls)):\n",
    "\t\t\turl = 'http://basketball-reference.com' + match_urls[i]\n",
    "\t\t\texception = True\n",
    "\t\t\twhile(exception):\n",
    "\t\t\t\ttry:\n",
    "\t\t\t\t\tresponse = requests.request(\"GET\", url)\n",
    "\t\t\t\t\tsoup = BeautifulSoup(response.content, 'html.parser')\n",
    "\t\t\t\t\texception = False\n",
    "\t\t\t\texcept requests.exceptions.RequestException as e:\n",
    "\t\t\t\t\tprint(e)\n",
    "\t\t\t\t\ttime.sleep(20)\n",
    "\t\t\t\t\texception = True\n",
    "\t\t\ttable = soup.findAll('table', attrs={'id': 'schedule'})\n",
    "\t\t\tdf = pd.read_html(str(table), flavor='bs4', header=[0])[0]\n",
    "\t\t\tdf.drop(columns=df.columns[[1,6,7,8,9]], inplace=True)\n",
    "\t\t\tdf.rename(columns={'Date':'date', 'Visitor/Neutral': 'away', \n",
    "\t\t\t\t'Home/Neutral': 'home', 'PTS': 'away_pts', 'PTS.1': 'home_pts'}, inplace=True)\n",
    "\n",
    "\t\t\tdf['date'] = pd.to_datetime(df.date)\n",
    "\t\t\tdf = df[df['away_pts'].notna()]\n",
    "\t\t\tdf['date'] = df['date'].dt.strftime('%Y%m%d')\n",
    "\t\t\tdf['away'] = df['away'].apply(lambda x: team_abbr[x])\n",
    "\t\t\tdf['home'] = df['home'].apply(lambda x: team_abbr[x])\n",
    "\t\t\tprint(df.columns)\n",
    "\t\t\tif i == 0:\n",
    "\t\t\t\tdf.to_csv(file_path, mode='a',index=False, header=True)\n",
    "\t\t\telse:\n",
    "\t\t\t\tdf.to_csv(file_path, mode='a',index=False, header=False)\n",
    "\texcept Exception as err:\n",
    "\t\traise err\n",
    "\n",
    "def seconder(x):\n",
    "    if x == 0:\n",
    "        return 0\n",
    "    mins, secs = map(float, x.split(':'))\n",
    "    td = timedelta(minutes=mins, seconds=secs)\n",
    "    return td.total_seconds()\n",
    "\n",
    "def match_data_to_csv(match_html):\n",
    "\t'''\n",
    "    match_data_to_csv saves the stats of every player in the match into a csv\n",
    "\n",
    "\tArgs: \n",
    "\t\t:param match_html: html of the given match \n",
    "\t\t\tbs4_html/boxscores/date+hometeam.html\n",
    "\t\n",
    "\t:side effect: csv with match stats\n",
    "    :return: None\n",
    "    '''\n",
    "\ttry:\n",
    "\t\twith open(match_html, 'r', encoding=\"utf8\") as f:\n",
    "\t\t\tcontents = f.read()\n",
    "\t\t\tsoup = BeautifulSoup(contents, 'lxml')\n",
    "\n",
    "\t\tline_score_table = soup.findAll(string=re.compile(\"div_line_score\"))\n",
    "\t\tteams = re.findall(\"teams\\/[A-Z]{3}\\/[0-9]{4}\", str(line_score_table))\n",
    "\n",
    "\t\tseason = teams[0][len(teams[0])-4:]\n",
    "\t\tteams = [teams[i][0:len(teams[0])-5].lstrip('teams/') for i in range(len(teams))]\n",
    "\n",
    "\t\tlinescores = re.findall('data-stat=\"[0-9]\" >[0-9]{1,}<', str(line_score_table))\n",
    "\t\tlinescores = [linescores[i][len(linescores[i])-3:-1] for i in range(len(linescores))]\n",
    "\n",
    "\n",
    "\t\tdirectory = \"csv/\" + season\n",
    "\t\tif not os.path.isdir(directory):\n",
    "\t\t\tos.makedirs(directory)\n",
    "\t\tfile_path = directory+\"/\"+re.findall(\"[0-9]{8}[A-Z]{3}\", match_html)[0] + \".csv\"\n",
    "\t\tif os.path.exists(file_path):\n",
    "\t\t\tos.remove(file_path)\n",
    "\n",
    "\t\ttable = soup.findAll('table')\n",
    "\t\tfor i in range(len(teams)):\n",
    "\t\t\tbasic_stat_tag = 'box-' + teams[i] + '-game-basic'\n",
    "\t\t\tadvanced_stat_tag = 'box-' + teams[i] + '-game-advanced'\n",
    "\n",
    "\t\t\tbasic_df = pd.read_html(str(table), flavor='bs4', \n",
    "\t\t\t\theader=[1], attrs= {'id': basic_stat_tag})[0]\n",
    "\n",
    "\t\t\tdf = pd.read_html(str(table), flavor='bs4', \n",
    "\t\t\t\theader=[1], attrs= {'id': advanced_stat_tag})[0]\n",
    "\n",
    "\t\t\tdf['team_name'] = teams[i]\n",
    "\t\t\tdf['starter'] = 1\n",
    "\t\t\tdf['date'] = re.findall(\"[0-9]{8}\", match_html)[0]\n",
    "\t\t\tstarter = True\n",
    "\t\t\tdrop_rows = []\n",
    "\t\t\tfor j in range(len(df)):\n",
    "\t\t\t\t\n",
    "\t\t\t\tif df.iloc[j,0] == 'Reserves':\n",
    "\t\t\t\t\tstarter = False\n",
    "\t\t\t\t\tdrop_rows.append(j)\n",
    "\t\t\t\telif df.iloc[j,0] == 'Team Totals':\n",
    "\t\t\t\t\tdrop_rows.append(j)\n",
    "\t\t\t\n",
    "\t\t\tdf[df == 'Did Not Play'] = 0\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\n",
    "\n",
    "\t\t\tdf.drop(drop_rows, inplace=True)\n",
    "\t\t\tbasic_df.drop(drop_rows, inplace=True)\n",
    "\t\t\tbasic_df.drop(['MP', 'Starters'], axis=1, inplace=True)\n",
    "\n",
    "\t\t\tdf['MP'] = df['MP'].apply(seconder)\n",
    "\t\t\n",
    "\t\t\tdf = pd.concat([df, basic_df], axis = 1)\n",
    "\t\t\tdf.rename(columns={'Starters': 'player_name', 'MP': 'sp',\n",
    "\t\t\t'TS%': 'ts_p', 'eFG%': 'efg_p', '3PAr':'three_par', 'FTr': 'ftr',\n",
    "\t\t\t'ORB%': 'orb_p', 'DRB%':'drb_p', 'TRB%': 'trb_p', 'AST%':'ast_p',\n",
    "\t\t\t'STL%': 'stl_p', 'BLK%':'blk_p', 'TOV%': 'tov_p', 'USG%': 'usg_p',\n",
    "\t\t\t'ORtg': 'ortg', 'DRtg':'drtg', 'BPM':'bpm', 'FG': 'fg',\n",
    "\t\t\t'FGA': 'fga', 'FG%': 'fg_p', '3P': 'three_p', '3PA': 'three_pa', '3P%': 'three_p_p',\n",
    "\t\t\t'FT': 'ft', 'FTA': 'fta', 'FT%': 'ft_p', 'ORB': 'orb',\n",
    "\t\t\t'DRB': 'drb', 'TRB': 'trb', 'AST': 'ast','STL': 'stl',\n",
    "\t\t\t'BLK': 'blk', 'TOV': 'tov', 'PF': 'pf', 'PTS': 'pts', '+/-': 'pm'}, inplace=True)\n",
    "\t\t\tprint(df.columns)\n",
    "\t\t\tif i ==0:\n",
    "\t\t\t\tdf.to_csv(file_path, mode='a',index=False, header=True)\n",
    "\t\t\telse:\n",
    "\t\t\t\tdf.to_csv(file_path, mode='a',index=False, header=False)\n",
    "\n",
    "\texcept Exception as err:\n",
    "\t\traise err\n",
    "\t\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "59ebddf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WAS', 'Troy Brown', 'Ian Mahinmi', 'John Wall', 'DAL', 'Ryan Broekhoff', 'Antonius Cleveland', 'Dwight Powell', 'Josh Reaves']\n",
      "Int64Index([0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13], dtype='int64')\n",
      "            player_name      sp  ts_p efg_p three_par    ftr orb_p drb_p  \\\n",
      "0           Luka Dončić  2011.0  .755  .737      .474   .421   3.5  22.0   \n",
      "1    Kristaps Porziņģis  1751.0  .603  .531      .438   .438   0.0  12.7   \n",
      "2           Maxi Kleber  1414.0  .000  .000     1.000   .000   5.0  27.4   \n",
      "3          Delon Wright  1288.0  .868  .750      .500  1.000   0.0  17.2   \n",
      "4          Courtney Lee   962.0  .400  .400      .600   .000   0.0   5.8   \n",
      "6   Dorian Finney-Smith  1932.0  .665  .375      .750  2.000   7.3  17.2   \n",
      "7         Jalen Brunson  1460.0  .383  .350      .300   .400   4.8  11.4   \n",
      "8          Tim Hardaway  1285.0  .286  .286      .714   .000   0.0   4.3   \n",
      "9            Seth Curry  1179.0  .654  .583      .333   .333   0.0  14.1   \n",
      "10       Justin Jackson  1118.0  .727  .667      .333   .333   0.0  19.8   \n",
      "11           J.J. Barea     0.0     0     0         0      0     0     0   \n",
      "12     Boban Marjanović     0.0     0     0         0      0     0     0   \n",
      "13          Isaiah Roby     0.0     0     0         0      0     0     0   \n",
      "14           Troy Brown     0.0     0     0         0      0     0     0   \n",
      "15          Ian Mahinmi     0.0     0     0         0      0     0     0   \n",
      "16            John Wall     0.0     0     0         0      0     0     0   \n",
      "17       Ryan Broekhoff     0.0     0     0         0      0     0     0   \n",
      "18   Antonius Cleveland     0.0     0     0         0      0     0     0   \n",
      "19        Dwight Powell     0.0     0     0         0      0     0     0   \n",
      "20          Josh Reaves     0.0     0     0         0      0     0     0   \n",
      "\n",
      "   trb_p ast_p stl_p blk_p tov_p usg_p ortg drtg    bpm team_name  starter  \\\n",
      "0   13.9  24.1   2.8   0.0  21.0  37.3  117   92   11.2       DAL        1   \n",
      "1    7.1  14.0   1.6   3.2  17.3  34.7  101   96    3.4       DAL        1   \n",
      "2   17.5   5.8   0.0  11.8  75.0   7.4   32   89   -3.9       DAL        1   \n",
      "3    9.6  20.5   2.2   0.0   0.0   5.9  190   95    7.4       DAL        1   \n",
      "4    3.2   0.0   0.0   0.0   0.0  13.7   79  104   -8.0       DAL        1   \n",
      "6   12.8   4.4   0.0   2.9   0.0  10.2  154   98    5.2       DAL        0   \n",
      "7    8.5  20.3   3.8   0.0  25.4  28.4   70   93   -7.2       DAL        0   \n",
      "8    2.4   7.3   0.0   0.0   0.0  14.3   66  104  -11.1       DAL        0   \n",
      "9    7.9   8.8   0.0   0.0  22.5  19.8  102  101   -2.1       DAL        0   \n",
      "10  11.1  20.9   0.0   0.0   0.0  16.2  153   99    8.0       DAL        0   \n",
      "11     0     0     0     0     0     0    0    0      0       DAL        0   \n",
      "12     0     0     0     0     0     0    0    0      0       DAL        0   \n",
      "13     0     0     0     0     0     0    0    0      0       DAL        0   \n",
      "14     0     0     0     0     0     0    0    0      0       WAS        0   \n",
      "15     0     0     0     0     0     0    0    0      0       WAS        0   \n",
      "16     0     0     0     0     0     0    0    0      0       WAS        0   \n",
      "17     0     0     0     0     0     0    0    0      0       DAL        0   \n",
      "18     0     0     0     0     0     0    0    0      0       DAL        0   \n",
      "19     0     0     0     0     0     0    0    0      0       DAL        0   \n",
      "20     0     0     0     0     0     0    0    0      0       DAL        0   \n",
      "\n",
      "    inactive      date  fg fga  fg_p three_p three_pa three_p_p ft fta   ft_p  \\\n",
      "0          0  20191023  12  19  .632       4        9      .444  6   8   .750   \n",
      "1          0  20191023   7  16  .438       3        7      .429  6   7   .857   \n",
      "2          0  20191023   0   1  .000       0        1      .000  0   0    NaN   \n",
      "3          0  20191023   1   2  .500       1        1     1.000  2   2  1.000   \n",
      "4          0  20191023   2   5  .400       0        3      .000  0   0    NaN   \n",
      "6          0  20191023   1   4  .250       1        3      .333  7   8   .875   \n",
      "7          0  20191023   3  10  .300       1        3      .333  2   4   .500   \n",
      "8          0  20191023   2   7  .286       0        5      .000  0   0    NaN   \n",
      "9          0  20191023   3   6  .500       1        2      .500  2   2  1.000   \n",
      "10         0  20191023   4   6  .667       0        2      .000  2   2  1.000   \n",
      "11         0  20191023   0   0     0       0        0         0  0   0      0   \n",
      "12         0  20191023   0   0     0       0        0         0  0   0      0   \n",
      "13         0  20191023   0   0     0       0        0         0  0   0      0   \n",
      "14         1  20191023   0   0     0       0        0         0  0   0      0   \n",
      "15         1  20191023   0   0     0       0        0         0  0   0      0   \n",
      "16         1  20191023   0   0     0       0        0         0  0   0      0   \n",
      "17         1  20191023   0   0     0       0        0         0  0   0      0   \n",
      "18         1  20191023   0   0     0       0        0         0  0   0      0   \n",
      "19         1  20191023   0   0     0       0        0         0  0   0      0   \n",
      "20         1  20191023   0   0     0       0        0         0  0   0      0   \n",
      "\n",
      "   orb drb trb ast stl blk tov pf pts   pm  \n",
      "0    1   8   9   3   2   0   6  4  34    0  \n",
      "1    0   4   4   2   1   1   4  2  23   +3  \n",
      "2    1   7   8   1   0   3   3  4   0   -3  \n",
      "3    0   4   4   3   1   0   0  1   5   +1  \n",
      "4    0   1   1   0   0   0   0  2   4   -4  \n",
      "6    2   6   8   1   0   1   0  0  10  +18  \n",
      "7    1   3   4   3   2   0   4  3   9   +2  \n",
      "8    0   1   1   1   0   0   0  4   4   +2  \n",
      "9    0   3   3   1   0   0   2  1   9  +11  \n",
      "10   0   4   4   2   0   0   0  1  10  +10  \n",
      "11   0   0   0   0   0   0   0  0   0    0  \n",
      "12   0   0   0   0   0   0   0  0   0    0  \n",
      "13   0   0   0   0   0   0   0  0   0    0  \n",
      "14   0   0   0   0   0   0   0  0   0    0  \n",
      "15   0   0   0   0   0   0   0  0   0    0  \n",
      "16   0   0   0   0   0   0   0  0   0    0  \n",
      "17   0   0   0   0   0   0   0  0   0    0  \n",
      "18   0   0   0   0   0   0   0  0   0    0  \n",
      "19   0   0   0   0   0   0   0  0   0    0  \n",
      "20   0   0   0   0   0   0   0  0   0    0  \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    match_data_to_csv saves the stats of every player in the match into a csv\n",
    "\n",
    "\tArgs: \n",
    "\t\t:param match_html: html of the given match \n",
    "\t\t\tbs4_html/boxscores/date+hometeam.html\n",
    "\t\n",
    "\t:side effect: csv with match stats\n",
    "    :return: None\n",
    "    '''\n",
    "try:\n",
    "    with open(match_html, 'r', encoding=\"utf8\") as f:\n",
    "        contents = f.read()\n",
    "        soup = BeautifulSoup(contents, 'lxml')\n",
    "\n",
    "    line_score_table = soup.findAll(string=re.compile(\"div_line_score\"))\n",
    "    teams = re.findall(\"teams\\/[A-Z]{3}\\/[0-9]{4}\", str(line_score_table))\n",
    "\n",
    "    season = teams[0][len(teams[0])-4:]\n",
    "    teams = [teams[i][0:len(teams[0])-5].lstrip('teams/') for i in range(len(teams))]\n",
    "\n",
    "    linescores = re.findall('data-stat=\"[0-9]\" >[0-9]{1,}<', str(line_score_table))\n",
    "    linescores = [linescores[i][len(linescores[i])-3:-1] for i in range(len(linescores))]\n",
    "\n",
    "\n",
    "    directory = \"csv/\" + season\n",
    "    if not os.path.isdir(directory):\n",
    "        os.makedirs(directory)\n",
    "    file_path = directory+\"/\"+re.findall(\"[0-9]{8}[A-Z]{3}\", match_html)[0] + \".csv\"\n",
    "    if os.path.exists(file_path):\n",
    "        os.remove(file_path)\n",
    "\n",
    "    table = soup.findAll('table')\n",
    "    for i in range(len(teams)):\n",
    "        basic_stat_tag = 'box-' + teams[i] + '-game-basic'\n",
    "        advanced_stat_tag = 'box-' + teams[i] + '-game-advanced'\n",
    "\n",
    "        basic_df = pd.read_html(str(table), flavor='bs4', \n",
    "            header=[1], attrs= {'id': basic_stat_tag})[0]\n",
    "\n",
    "        df = pd.read_html(str(table), flavor='bs4', \n",
    "            header=[1], attrs= {'id': advanced_stat_tag})[0]\n",
    "\n",
    "        df['team_name'] = teams[i]\n",
    "        df['starter'] = 1\n",
    "        df['inactive'] = 0\n",
    "        df['date'] = re.findall(\"[0-9]{8}\", match_html)[0]\n",
    "        starter = True\n",
    "        drop_rows = []\n",
    "        df.replace({'Did Not Play': 0, 'Nan': 0}, regex=True, inplace=True)\n",
    "        basic_df.replace({'Did Not Play': 0, 'Nan': 0}, regex=True, inplace=True)\n",
    "\n",
    "        for j in range(len(df)):\n",
    "\n",
    "            if df.iloc[j,0] == 'Reserves':\n",
    "                starter = False\n",
    "                drop_rows.append(j)\n",
    "            elif df.iloc[j,0] == 'Team Totals':\n",
    "                drop_rows.append(j)\n",
    "            else:\n",
    "                df.loc[j,'starter'] = int(starter)\n",
    "\n",
    "        df.drop(drop_rows, inplace=True)\n",
    "        basic_df.drop(drop_rows, inplace=True)\n",
    "        basic_df.drop(['MP', 'Starters'], axis=1, inplace=True)\n",
    "\n",
    "        df['MP'] = df['MP'].apply(seconder)\n",
    "        df = pd.concat([df, basic_df], axis = 1)\n",
    "        df.rename(columns={'Starters': 'player_name', 'MP': 'sp',\n",
    "        'TS%': 'ts_p', 'eFG%': 'efg_p', '3PAr':'three_par', 'FTr': 'ftr',\n",
    "        'ORB%': 'orb_p', 'DRB%':'drb_p', 'TRB%': 'trb_p', 'AST%':'ast_p',\n",
    "        'STL%': 'stl_p', 'BLK%':'blk_p', 'TOV%': 'tov_p', 'USG%': 'usg_p',\n",
    "        'ORtg': 'ortg', 'DRtg':'drtg', 'BPM':'bpm', 'FG': 'fg',\n",
    "        'FGA': 'fga', 'FG%': 'fg_p', '3P': 'three_p', '3PA': 'three_pa', '3P%': 'three_p_p',\n",
    "        'FT': 'ft', 'FTA': 'fta', 'FT%': 'ft_p', 'ORB': 'orb',\n",
    "        'DRB': 'drb', 'TRB': 'trb', 'AST': 'ast','STL': 'stl',\n",
    "        'BLK': 'blk', 'TOV': 'tov', 'PF': 'pf', 'PTS': 'pts', '+/-': 'pm'}, inplace=True)\n",
    "\n",
    "        if i ==0:\n",
    "            df.to_csv(file_path, mode='a',index=False, header=True)\n",
    "        else:\n",
    "            inactive = re.findall(\"Inactive:.*div\", str(soup))\n",
    "            inactive = re.findall(\">[A-Za-z ]+<\", inactive[0])\n",
    "            inactive = [s.rstrip('<').lstrip('>') for s in inactive]\n",
    "            match_date = df.loc[0, 'date']\n",
    "            print(inactive)\n",
    "            print(df.index)\n",
    "            for i in range(len(inactive)):\n",
    "                if inactive[i] == teams[0] or inactive[i] == teams[1]:\n",
    "                    team = inactive[i]\n",
    "                else:\n",
    "                    row = [0]*len(df.iloc[0])\n",
    "                    df.loc[df.index[-1]+1] = row\n",
    "                    df.loc[df.index[-1],'player_name'] = inactive[i]\n",
    "                    df.loc[df.index[-1],'team_name'] = team\n",
    "                    df.loc[df.index[-1],'date'] = match_date\n",
    "                    df.loc[df.index[-1], 'inactive'] = 1\n",
    "\n",
    "            print(df)\n",
    "            df.to_csv(file_path, mode='a',index=False, header=False)\n",
    "        \n",
    "except Exception as err:\n",
    "    raise err\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e16f5c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-46-1bece277f51b>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-46-1bece277f51b>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    if inactive[i] == teams[0] || inactive[i] == teams[1]:\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "match_html = \"bs4_html/boxscores/201910230DAL.html\"\n",
    "with open(match_html, 'r', encoding=\"utf8\") as f:\n",
    "    contents = f.read()\n",
    "    soup = BeautifulSoup(contents, 'lxml')\n",
    "    inactive = re.findall(\"Inactive:.*div\", str(soup))\n",
    "    inactive = re.findall(\">[A-Za-z ]+<\", inactive[0])\n",
    "    inactive = [s.rstrip('<').lstrip('>') for s in inactive]\n",
    "    print(inactive)\n",
    "    for i in range(len(inactive)):\n",
    "        if inactive[i] == teams[0] || inactive[i] == teams[1]:\n",
    "            team = inactive[i]\n",
    "        else:\n",
    "            row = [inactive[i], [0]**16 , team, 0, df.iloc[0,-1]]\n",
    "            df.loc[len(df)] = row\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab98841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "team = \"DAL\"\n",
    "date = \"201910230\"\n",
    "match_id = '1'\n",
    "#shd.save_boxscore_html(team, date)\n",
    "html_path = \"bs4_html/boxscores/201910230DAL.html\"\n",
    "#shd.save_player_data(html_path)\n",
    "#shd.save_match_html('2021')\n",
    "save_match_data('bs4_html/match_list/2021.html')\n",
    "#shd.save_all_player_performances('2021')\n",
    "conn=db_func.get_conn()\n",
    "cur = conn.cursor()\n",
    "res = imp.get_all_matches(cur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "14ce70f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_html(url, file):\n",
    "\t\"\"\"\n",
    "    save_html saves the html page for a given match (boxscores)\n",
    "\t\n",
    "\tArgs: \n",
    "\t\tparam team: home team of match\n",
    "\t\tparam date: date of match\n",
    "\t\n",
    "\t:side effect: saves the respective html page in bs4_html/boxscores/date+team.html\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "\ttry:\n",
    "\t\texception = True\n",
    "\n",
    "\t\twhile(exception):\n",
    "\t\t\ttry:\n",
    "\t\t\t\tresponse = requests.request(\"GET\", url)\n",
    "\t\t\t\tsoup = BeautifulSoup(response.content, 'html.parser')\n",
    "\t\t\t\texception = False\n",
    "\t\t\texcept requests.exceptions.RequestException as e:\n",
    "\t\t\t\tprint(e)\n",
    "\t\t\t\ttime.sleep(20)\n",
    "\t\t\t\texception = True\n",
    "\t\tif not os.path.isdir(\"bs4_html\"):\n",
    "\t\t\tos.makedirs(\"bs4_html\")\n",
    "\t\tos.makedirs(os.path.dirname(file), exist_ok=True)\n",
    "\t\twith open(file, \"w\", encoding='utf-8') as f:\n",
    "\t\t\tf.write(str(soup))\n",
    "\texcept Exception as err:\n",
    "\t\tprint(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7e6477dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.basketball-reference.com/teams/PHI/2021.html'\n",
    "\n",
    "\n",
    "html = os.path.join(os.getcwd(),\"bs4_html/roster/\" + season + \\\n",
    "    \"/PHI.html\")\n",
    "save_html(url, html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f5400466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Danny Green SF /players/g/greenda02.html\n",
      "Dwight Howard C /players/h/howardw01.html\n",
      "Matisse Thybulle SG /players/t/thybuma01.html\n",
      "Shake Milton SG /players/m/miltosh01.html\n",
      "Tobias Harris PF /players/h/harrito02.html\n",
      "Tyrese Maxey SG /players/m/maxeyty01.html\n",
      "Ben Simmons PG /players/s/simmobe01.html\n",
      "Seth Curry SG /players/c/curryse01.html\n",
      "Furkan Korkmaz SG /players/k/korkmfu01.html\n",
      "Joel Embiid C /players/e/embiijo01.html\n",
      "Mike Scott PF /players/s/scottmi01.html\n",
      "Isaiah Joe SG /players/j/joeis01.html\n",
      "Paul Reed PF /players/r/reedpa01.html\n",
      "George Hill PG /players/h/hillge01.html\n",
      "Rayjon Tucker PG /players/t/tuckera01.html\n",
      "Anthony Tolliver PF /players/t/tollian01.html\n",
      "Gary Clark PF /players/c/clarkga01.html\n"
     ]
    }
   ],
   "source": [
    "html = os.path.join(os.getcwd(),\"bs4_html/roster/\" + season + \\\n",
    "    \"/PHI.html\")\n",
    "with open(html, 'r', encoding=\"utf8\") as f:\n",
    "    contents = f.read()\n",
    "    soup = BeautifulSoup(contents, 'lxml')\n",
    "\n",
    "    roster_table = soup.find('table', attrs={'id': 'roster'})\n",
    "    player=[]  \n",
    "\n",
    "    trs = roster_table.findAll('tr')\n",
    "    for i in range(1,len(trs)):\n",
    "        name = trs[i].a.text\n",
    "        url = trs[i].a['href']\n",
    "        pos = trs[i].find('td', attrs={'data-stat':'pos'}).text\n",
    "        print(name, pos, url)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a6ff17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
